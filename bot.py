import logging
import sqlite3
import json
import re
import os
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from urllib.parse import urlparse
import asyncio
import aiohttp
from dataclasses import dataclass

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, CallbackQueryHandler, filters, ContextTypes

# ×¡×¤×¨×™×•×ª ×—×™×¦×•× ×™×•×ª × ×“×¨×©×•×ª
try:
    from newspaper import Article
    import openai
    from transformers import pipeline
except ImportError:
    print("× ×“×¨×©×•×ª ×¡×¤×¨×™×•×ª × ×•×¡×¤×•×ª: pip install newspaper3k openai transformers torch")

# ×”×’×“×¨×•×ª
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

# ×”×’×“×¨×•×ª ×§×‘×•×¢×•×ª
TELEGRAM_TOKEN = "7560439844:AAEEVJwLFO44j7QoxZNULRlYlZMKeRK3yP0"
OPENAI_API_KEY = "YOUR_OPENAI_API_KEY"  # ××•×¤×¦×™×•× ×œ×™
DB_PATH = "read_later.db"

@dataclass
class SavedArticle:
    id: int
    url: str
    title: str
    summary: str
    full_text: str
    category: str
    tags: str
    date_saved: str
    user_id: int

class ReadLaterBot:
    def __init__(self, use_openai: bool = False):
        self.use_openai = use_openai
        if use_openai:
            openai.api_key = OPENAI_API_KEY
        # ×”×¡×¨× ×• ××ª HuggingFace summarizer ×›×™ PyTorch ×™×§×¨ ××“×™
        
        self.init_database()
        
    def init_database(self):
        """×™×¦×™×¨×ª ××¡×“ × ×ª×•× ×™×"""
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS articles (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id INTEGER NOT NULL,
                url TEXT NOT NULL,
                title TEXT NOT NULL,
                summary TEXT NOT NULL,
                full_text TEXT NOT NULL,
                category TEXT DEFAULT '×›×œ×œ×™',
                tags TEXT DEFAULT '',
                date_saved TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def extract_article_content(self, url: str) -> Optional[Dict]:
        """×”×•×¦××ª ×ª×•×›×Ÿ ××›×ª×‘×” ×‘×××¦×¢×•×ª Newspaper3k"""
        try:
            # × ×¡×” ×¢× User-Agent ×›×“×™ ×œ× ×œ×”×™×—×¡×
            article = Article(url, language='he')
            article.config.browser_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            article.config.request_timeout = 10
            
            article.download()
            article.parse()
            
            # ×× ×œ× ××¦×× ×• ×ª×•×›×Ÿ ×‘×¢×‘×¨×™×ª, × × ×¡×” ×‘×× ×’×œ×™×ª
            if not article.text.strip():
                article = Article(url, language='en')
                article.config.browser_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                article.download()
                article.parse()
            
            if not article.text.strip():
                logger.error(f"No content found for URL: {url}")
                return None
                
            return {
                'title': article.title or '×›×•×ª×¨×ª ×œ× ×–××™× ×”',
                'text': article.text,
                'authors': article.authors,
                'publish_date': article.publish_date
            }
            
        except Exception as e:
            logger.error(f"Error extracting content from {url}: {str(e)}")
            # × ×—×–×™×¨ ×¤×¨×˜×™ ×”×©×’×™××” ×œ×¦×•×¨×š debug
            return {'error': str(e), 'url': url}
    
    def extract_content_fallback(self, url: str) -> Optional[Dict]:
        """×©×™×˜×” ×—×œ×•×¤×™×ª ×œ×”×•×¦××ª ×ª×•×›×Ÿ"""
        try:
            import requests
            from bs4 import BeautifulSoup
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ×—×¤×© ×›×•×ª×¨×ª
            title = None
            for selector in ['h1', 'title', '.headline', '.title']:
                title_elem = soup.select_one(selector)
                if title_elem and title_elem.get_text().strip():
                    title = title_elem.get_text().strip()
                    break
            
            # ×—×¤×© ×ª×•×›×Ÿ
            text = ""
            for selector in ['article', '.content', '.article-body', 'main', '.post-content']:
                content_elem = soup.select_one(selector)
                if content_elem:
                    text = content_elem.get_text().strip()
                    break
            
            if not text:
                # ×× ×œ× ××¦×× ×•, ×§×— ××ª ×›×œ ×”×¤×¡×§××•×ª
                paragraphs = soup.find_all('p')
                text = '\n'.join([p.get_text().strip() for p in paragraphs if p.get_text().strip()])
            
            if title and text:
                return {
                    'title': title[:200],  # ×”×’×‘×œ ××•×¨×š ×›×•×ª×¨×ª
                    'text': text[:5000],   # ×”×’×‘×œ ××•×¨×š ×˜×§×¡×˜
                    'authors': [],
                    'publish_date': None
                }
            
            return None
            
        except Exception as e:
            logger.error(f"Fallback extraction failed for {url}: {str(e)}")
            return None
    
    def summarize_text(self, text: str, max_length: int = 150) -> str:
        """×¡×™×›×•× ×˜×§×¡×˜ ×‘×××¦×¢×•×ª AI"""
        try:
            if self.use_openai:
                response = openai.ChatCompletion.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "××ª×” ××¡×›× ×›×ª×‘×•×ª ×‘×¢×‘×¨×™×ª. ×¦×•×¨ ×¡×™×›×•× ×§×¦×¨ ×•×—×“ ×©×œ ×”×›×ª×‘×”."},
                        {"role": "user", "content": f"×¡×›× ××ª ×”×›×ª×‘×” ×”×–×•: {text[:3000]}"}
                    ],
                    max_tokens=max_length,
                    temperature=0.3
                )
                return response.choices[0].message.content
            else:
                # ×¡×™×›×•× ×¤×©×•×˜ ×œ×œ× HuggingFace
                sentences = text.split('.')[:3]  # 3 ××©×¤×˜×™× ×¨××©×•× ×™×
                summary = '. '.join(sentences).strip()
                if len(summary) > max_length:
                    summary = summary[:max_length] + "..."
                return summary or "×¡×™×›×•× ×œ× ×–××™×Ÿ"
                
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×¡×™×›×•×: {e}")
            return "×¡×™×›×•× ×œ× ×–××™×Ÿ"
    
    def detect_category(self, title: str, text: str) -> str:
        """×–×™×”×•×™ ×§×˜×’×•×¨×™×” ××•×˜×•××˜×™"""
        categories = {
            '×˜×›× ×•×œ×•×’×™×”': ['×˜×›× ×•×œ×•×’×™×”', '××¤×œ×™×§×¦×™×”', '×¡×××¨×˜×¤×•×Ÿ', '××—×©×‘', '××™× ×˜×¨× ×˜', '×¡×™×™×‘×¨', 'AI', '×‘×™× ×” ××œ××›×•×ª×™×ª'],
            '×‘×¨×™××•×ª': ['×‘×¨×™××•×ª', '×¨×¤×•××”', '××—×§×¨', '×˜×™×¤×•×œ', '×ª×–×•× ×”', '×¡×¤×•×¨×˜', '×›×•×©×¨'],
            '×›×œ×›×œ×”': ['×›×œ×›×œ×”', '×›×¡×¤×™×', '×”×©×§×¢×•×ª', '×‘×•×¨×¡×”', '×¢×¡×§×™×', '×—×‘×¨×”', '×¡×˜××¨×˜××¤'],
            '×¤×•×œ×™×˜×™×§×”': ['×¤×•×œ×™×˜×™×§×”', '×××©×œ×”', '×›× ×¡×ª', '×‘×—×™×¨×•×ª', '××“×™× ×”', '×—×•×§'],
            '×”×©×¨××”': ['×”×©×¨××”', '××•×˜×™×‘×¦×™×”', '××™×©×™×•×ª', '×”×¦×œ×—×”', '×—×œ×•××•×ª', '××˜×¨×•×ª']
        }
        
        full_text = f"{title} {text}".lower()
        
        for category, keywords in categories.items():
            if any(keyword.lower() in full_text for keyword in keywords):
                return category
        
        return '×›×œ×œ×™'
    
    def save_article(self, user_id: int, url: str, title: str, summary: str, 
                    full_text: str, category: str = '×›×œ×œ×™', tags: str = '') -> int:
        """×©××™×¨×ª ×›×ª×‘×” ×‘××¡×“ × ×ª×•× ×™×"""
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO articles (user_id, url, title, summary, full_text, category, tags)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        ''', (user_id, url, title, summary, full_text, category, tags))
        
        article_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        return article_id
    
    def get_user_articles(self, user_id: int, category: str = None) -> List[SavedArticle]:
        """×©×œ×™×¤×ª ×›×ª×‘×•×ª ×©×œ ××©×ª××©"""
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        if category:
            cursor.execute('''
                SELECT id, url, title, summary, full_text, category, tags, date_saved, user_id 
                FROM articles WHERE user_id = ? AND category = ?
                ORDER BY date_saved DESC
            ''', (user_id, category))
        else:
            cursor.execute('''
                SELECT id, url, title, summary, full_text, category, tags, date_saved, user_id 
                FROM articles WHERE user_id = ?
                ORDER BY date_saved DESC
            ''', (user_id,))
        
        articles = []
        for row in cursor.fetchall():
            articles.append(SavedArticle(*row))
        
        conn.close()
        return articles
    
    def update_article_category(self, article_id: int, category: str, tags: str = None):
        """×¢×“×›×•×Ÿ ×§×˜×’×•×¨×™×” ×•×ª×’×™×•×ª"""
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        if tags:
            cursor.execute('''
                UPDATE articles SET category = ?, tags = ? WHERE id = ?
            ''', (category, tags, article_id))
        else:
            cursor.execute('''
                UPDATE articles SET category = ? WHERE id = ?
            ''', (category, article_id))
        
        conn.commit()
        conn.close()
    
    def delete_article(self, article_id: int, user_id: int):
        """××—×™×§×ª ×›×ª×‘×”"""
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        cursor.execute('''
            DELETE FROM articles WHERE id = ? AND user_id = ?
        ''', (article_id, user_id))
        
        conn.commit()
        conn.close()
    
    def export_articles(self, user_id: int, format_type: str = 'json') -> str:
        """×™×¦×•× ×›×ª×‘×•×ª ×œ×’×™×‘×•×™"""
        articles = self.get_user_articles(user_id)
        
        if format_type == 'json':
            data = []
            for article in articles:
                data.append({
                    'title': article.title,
                    'url': article.url,
                    'summary': article.summary,
                    'category': article.category,
                    'tags': article.tags,
                    'date_saved': article.date_saved
                })
            return json.dumps(data, ensure_ascii=False, indent=2)
        
        else:  # text format
            text = "×”×›×ª×‘×•×ª ×”×©××•×¨×•×ª ×©×œ×™:\n\n"
            for article in articles:
                # ×—×™×œ×•×¥ ×ª××¨×™×š ×‘×œ×™ ×©×¢×”
                date_only = article.date_saved.split(' ')[0]  # ×œ×•×§×— ×¨×§ ×”×—×œ×§ ×œ×¤× ×™ ×”×¨×•×•×—
                
                text += f"ğŸ“° {article.title}\n"
                text += f"ğŸ”— {article.url}\n"
                text += f"ğŸ“‚ {article.category}\n"
                text += f"ğŸ“… {date_only}\n"
                text += f"ğŸ“ {article.summary}\n\n"
                text += "â”€" * 50 + "\n\n"
            
            return text

# ×”×’×“×¨×ª ×”×‘×•×˜
bot = ReadLaterBot(use_openai=False)  # ×©× ×” ×œ-True ×× ×™×© ×œ×š OpenAI API key

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """×¤×§×•×“×ª ×”×ª×—×œ×”"""
    welcome_message = """
ğŸ“š ×©×œ×•× ×•×‘×¨×•×š ×”×‘× ×œ"×©××•×¨ ×œ×™ ×œ×§×¨×•× ××—×¨ ×›×š"! 

ğŸ”¸ ×©×œ×— ×œ×™ ×§×™×©×•×¨ ×œ×›×ª×‘×”, ×•×× ×™ ××¡×›× ×•××©××•×¨ ××•×ª×” ×œ×š ×‘××§×•× ××¡×•×“×¨.
ğŸ”¸ ×”×©×ª××© ×‘-/saved ×›×“×™ ×œ×¨××•×ª ××ª ×›×œ ×”×›×ª×‘×•×ª ×©×œ×š
ğŸ”¸ ×”×©×ª××© ×‘-/help ×œ×¢×–×¨×” × ×•×¡×¤×ª

×§×“×™××”, ×©×œ×— ×œ×™ ×§×™×©×•×¨ ×œ×›×ª×‘×” ××¢× ×™×™× ×ª! ğŸš€
"""
    await update.message.reply_text(welcome_message)

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """×¤×§×•×“×ª ×¢×–×¨×”"""
    help_text = """
ğŸ“– ××™×š ×œ×”×©×ª××© ×‘×‘×•×˜:

ğŸ”¸ **×©×œ×™×—×ª ×§×™×©×•×¨**: ×¤×©×•×˜ ×©×œ×— ×§×™×©×•×¨ ×œ×›×ª×‘×” ×•×× ×™ ××©××•×¨ ××•×ª×” ××•×˜×•××˜×™×ª
ğŸ”¸ **/saved** - ×¦×¤×™×™×” ×‘×›×œ ×”×›×ª×‘×•×ª ×”×©××•×¨×•×ª ×©×œ×š
ğŸ”¸ **/backup** - ×’×™×‘×•×™ ×˜×§×¡×˜ × ×— ×œ×§×¨×™××” (××• `/backup json` ×œ×§×•×‘×¥ ×˜×›× ×™)
ğŸ”¸ **/tag [××¡×¤×¨] [×§×˜×’×•×¨×™×”] [×ª×’×™×ª]** - ×¢×“×›×•×Ÿ ×§×˜×’×•×¨×™×” ×•×ª×’×™×•×ª
   ×“×•×’××”: /tag 3 AI ×—×©×•×‘

ğŸ“‚ **×§×˜×’×•×¨×™×•×ª ××•×˜×•××˜×™×•×ª**:
â€¢ ×˜×›× ×•×œ×•×’×™×” â€¢ ×‘×¨×™××•×ª â€¢ ×›×œ×›×œ×” â€¢ ×¤×•×œ×™×˜×™×§×” â€¢ ×”×©×¨××” â€¢ ×›×œ×œ×™
"""
    await update.message.reply_text(help_text)



async def handle_url(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """×˜×™×¤×•×œ ×‘×§×™×©×•×¨×™×"""
    url = update.message.text.strip()
    user_id = update.effective_user.id
    
    # ×‘×“×™×§×” ×©×–×” ××›×Ÿ ×§×™×©×•×¨
    if not re.match(r'https?://', url):
        await update.message.reply_text("×× × ×©×œ×— ×§×™×©×•×¨ ×ª×§×™×Ÿ (××ª×—×™×œ ×‘-http ××• https)")
        return
    
    # ×”×•×“×¢×ª ×˜×¢×™× ×”
    loading_message = await update.message.reply_text("ğŸ”„ ××¢×‘×“ ××ª ×”×›×ª×‘×”...")
    
    # ×”×•×¦××ª ×ª×•×›×Ÿ
    article_data = bot.extract_article_content(url)
    
    # ×× ×™×© ×©×’×™××”, × ×¦×™×’ ××•×ª×”
    if article_data and 'error' in article_data:
        error_msg = f"âŒ ×©×’×™××” ×‘×˜×¢×™× ×ª ×”×›×ª×‘×”:\n{article_data['error']}\n\n× × ×¡×” ×©×™×˜×” ××—×¨×ª..."
        await loading_message.edit_text(error_msg)
        
        # × ×¡×” ×©×™×˜×” ×—×œ×•×¤×™×ª
        article_data = bot.extract_content_fallback(url)
    
    if not article_data or 'error' in article_data:
        error_details = ""
        if article_data and 'error' in article_data:
            error_details = f"\n\n×¤×¨×˜×™ ×”×©×’×™××”: {article_data['error']}"
        
        await loading_message.edit_text(
            f"âŒ ××¦×˜×¢×¨, ×œ× ×”×¦×œ×—×ª×™ ×œ×˜×¢×•×Ÿ ××ª ×”×›×ª×‘×” ×”×–×•.\n\n"
            f"ğŸ”— ×§×™×©×•×¨: {url}\n"
            f"ğŸ’¡ × ×¡×”:\n"
            f"â€¢ ×œ×‘×“×•×§ ×©×”×§×™×©×•×¨ ×ª×§×™×Ÿ\n"
            f"â€¢ ×œ× ×¡×•×ª ×›×ª×‘×” ×××ª×¨ ××—×¨\n"
            f"â€¢ ×œ×©×œ×•×— ×§×™×©×•×¨ ×™×©×™×¨ ×œ×›×ª×‘×” (×œ× ×œ×¢××•×“ ×”×‘×™×ª)"
            f"{error_details}"
        )
        return
    
    # ×¡×™×›×•× ×”×ª×•×›×Ÿ
    await loading_message.edit_text("ğŸ¤– ××›×™×Ÿ ×¡×™×›×•×...")
    summary = bot.summarize_text(article_data['text'])
    
    # ×–×™×”×•×™ ×§×˜×’×•×¨×™×”
    category = bot.detect_category(article_data['title'], article_data['text'])
    
    # ×©××™×¨×” ×‘××¡×“ × ×ª×•× ×™×
    article_id = bot.save_article(
        user_id=user_id,
        url=url,
        title=article_data['title'],
        summary=summary,
        full_text=article_data['text'],
        category=category
    )
    
    # ×”×›× ×ª ×ª×’×•×‘×” ×¢× ×›×¤×ª×•×¨×™×
    keyboard = [
        [
            InlineKeyboardButton("ğŸ“‚ ×©× ×” ×§×˜×’×•×¨×™×”", callback_data=f"change_category_{article_id}"),
            InlineKeyboardButton("ğŸ” ×”×¦×’ ××œ×", callback_data=f"show_full_{article_id}")
        ],
        [
            InlineKeyboardButton("ğŸ—‘ï¸ ××—×§", callback_data=f"delete_{article_id}")
        ]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    # ×”×¦×’×ª ××™×“×¢ ×¢×œ ×”×›×ª×‘×”
    article_info = ""
    if article_data.get('authors'):
        article_info += f"âœï¸ **×›×•×ª×‘**: {', '.join(article_data['authors'])}\n"
    if article_data.get('publish_date'):
        article_info += f"ğŸ“… **×ª××¨×™×š**: {article_data['publish_date']}\n"
    
    response_text = f"""
âœ… **×”×›×ª×‘×” × ×©××¨×” ×‘×”×¦×œ×—×”!**

ğŸ“° **×›×•×ª×¨×ª**: {article_data['title']}
ğŸ“‚ **×§×˜×’×•×¨×™×”**: {category}
{article_info}
ğŸ“ **×¡×™×›×•×**:
{summary}

ğŸ”— **×§×™×©×•×¨**: {url}
"""
    
    await loading_message.edit_text(response_text, reply_markup=reply_markup, parse_mode='Markdown')

async def saved_articles(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """×”×¦×’×ª ×›×ª×‘×•×ª ×©××•×¨×•×ª"""
    user_id = update.effective_user.id
    articles = bot.get_user_articles(user_id)
    
    if not articles:
        await update.message.reply_text("××™×Ÿ ×œ×š ×›×ª×‘×•×ª ×©××•×¨×•×ª ×¢×“×™×™×Ÿ. ×©×œ×— ×œ×™ ×§×™×©×•×¨ ×›×“×™ ×œ×”×ª×—×™×œ! ğŸ“š")
        return
    
    # ×§×™×‘×•×¥ ×œ×¤×™ ×§×˜×’×•×¨×™×•×ª
    categories = {}
    for article in articles:
        if article.category not in categories:
            categories[article.category] = []
        categories[article.category].append(article)
    
    response = "ğŸ“š **×”×›×ª×‘×•×ª ×”×©××•×¨×•×ª ×©×œ×š:**\n\n"
    
    for category, cat_articles in categories.items():
        response += f"ğŸ“‚ **{category}** ({len(cat_articles)} ×›×ª×‘×•×ª)\n"
        for i, article in enumerate(cat_articles[:5], 1):  # ×”×¦×’ ×¨×§ 5 ×¨××©×•× ×•×ª
            response += f"{i}. {article.title[:60]}{'...' if len(article.title) > 60 else ''}\n"
        
        if len(cat_articles) > 5:
            response += f"   ... ×•×¢×•×“ {len(cat_articles) - 5} ×›×ª×‘×•×ª\n"
        response += "\n"
    
    # ×”×•×¡×¤×ª ×›×¤×ª×•×¨×™× ×œ×¤×¢×•×œ×•×ª
    keyboard = [
        [InlineKeyboardButton("ğŸ“Š ×¡×˜×˜×™×¡×˜×™×§×•×ª", callback_data="stats")],
        [InlineKeyboardButton("ğŸ’¾ ×’×™×‘×•×™", callback_data="backup")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await update.message.reply_text(response, reply_markup=reply_markup, parse_mode='Markdown')

async def button_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """×˜×™×¤×•×œ ×‘×œ×—×™×¦×•×ª ×¢×œ ×›×¤×ª×•×¨×™×"""
    query = update.callback_query
    await query.answer()
    
    data = query.data
    user_id = update.effective_user.id
    
    if data.startswith("show_full_"):
        article_id = int(data.split("_")[2])
        # ×”×¦×’×ª ×˜×§×¡×˜ ××œ× (××§×•×¦×¨)
        await query.edit_message_text("ğŸ” ×”×ª×›×•× ×” ×”×–×• ×‘×¤×™×ª×•×—...")
        
    elif data.startswith("delete_"):
        article_id = int(data.split("_")[1])
        bot.delete_article(article_id, user_id)
        await query.edit_message_text("ğŸ—‘ï¸ ×”×›×ª×‘×” × ××—×§×” ×‘×”×¦×œ×—×”")
        
    elif data == "backup":
        # ×™×¦×™×¨×ª ×’×™×‘×•×™
        backup_data = bot.export_articles(user_id, 'json')
        
        # ×©××™×¨×ª ×”×§×•×‘×¥
        filename = f"backup_{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(backup_data)
        
        await query.edit_message_text("ğŸ’¾ ×”×’×™×‘×•×™ ××•×›×Ÿ! ×”×§×•×‘×¥ × ×©××¨ ×‘×©×¨×ª.")
        
    elif data == "stats":
        articles = bot.get_user_articles(user_id)
        categories = {}
        for article in articles:
            categories[article.category] = categories.get(article.category, 0) + 1
        
        stats_text = f"ğŸ“Š **×”×¡×˜×˜×™×¡×˜×™×§×•×ª ×©×œ×š:**\n\n"
        stats_text += f"ğŸ“š ×¡×”\"×› ×›×ª×‘×•×ª: {len(articles)}\n\n"
        
        for category, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):
            stats_text += f"ğŸ“‚ {category}: {count} ×›×ª×‘×•×ª\n"
        
        await query.edit_message_text(stats_text, parse_mode='Markdown')

async def tag_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """×¤×§×•×“×ª ×ª×™×•×’"""
    if not context.args or len(context.args) < 2:
        await update.message.reply_text("×©×™××•×©: /tag [××¡×¤×¨_×›×ª×‘×”] [×§×˜×’×•×¨×™×”] [×ª×’×™×ª_××•×¤×¦×™×•× ×œ×™×ª]")
        return
    
    try:
        article_id = int(context.args[0])
        category = context.args[1]
        tags = ' '.join(context.args[2:]) if len(context.args) > 2 else ''
        
        bot.update_article_category(article_id, category, tags)
        await update.message.reply_text(f"âœ… ×”×›×ª×‘×” ×¢×•×“×›× ×”: ×§×˜×’×•×¨×™×” '{category}'{f', ×ª×’×™×•×ª: {tags}' if tags else ''}")
        
    except ValueError:
        await update.message.reply_text("âŒ ××¡×¤×¨ ×”×›×ª×‘×” ×—×™×™×‘ ×œ×”×™×•×ª ××¡×¤×¨")
    except Exception as e:
        await update.message.reply_text(f"âŒ ×©×’×™××”: {str(e)}")

async def backup_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """×¤×§×•×“×ª ×’×™×‘×•×™"""
    user_id = update.effective_user.id
    articles = bot.get_user_articles(user_id)
    
    if not articles:
        await update.message.reply_text("××™×Ÿ ×œ×š ×›×ª×‘×•×ª ×©××•×¨×•×ª ×œ×’×™×‘×•×™. ×©×œ×— ×œ×™ ×§×™×©×•×¨ ×›×“×™ ×œ×”×ª×—×™×œ! ğŸ“š")
        return
    
    # ×‘×“×™×§×” ××™×–×” ×¤×•×¨××˜ ×”×ª×‘×§×©
    format_type = 'text'  # ×‘×¨×™×¨×ª ××—×“×œ - ×˜×§×¡×˜ × ×— ×œ×§×¨×™××”
    if context.args and context.args[0].lower() == 'json':
        format_type = 'json'
    
    # ×™×¦×™×¨×ª ×’×™×‘×•×™
    backup_data = bot.export_articles(user_id, format_type)
    
    # ×©××™×¨×ª ×”×§×•×‘×¥
    file_extension = 'txt' if format_type == 'text' else 'json'
    filename = f"backup_{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{file_extension}"
    
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(backup_data)
        
        # ×©×œ×™×—×ª ×”×§×•×‘×¥ ×œ××©×ª××©
        with open(filename, 'rb') as f:
            display_filename = f"×›×ª×‘×•×ª_×©××•×¨×•×ª_{datetime.now().strftime('%Y-%m-%d')}.{file_extension}"
            format_desc = "×§×•×‘×¥ ×˜×§×¡×˜ × ×— ×œ×§×¨×™××”" if format_type == 'text' else "×§×•×‘×¥ JSON ×˜×›× ×™"
            
            await update.message.reply_document(
                document=f,
                filename=display_filename,
                caption=f"ğŸ’¾ **×’×™×‘×•×™ ×”×›×ª×‘×•×ª ×©×œ×š** ({format_desc})\n\nğŸ“š {len(articles)} ×›×ª×‘×•×ª\nğŸ“… {datetime.now().strftime('%d/%m/%Y %H:%M')}\n\nğŸ’¡ ×œ×’×™×‘×•×™ JSON ×˜×›× ×™ ×”×©×ª××©: `/backup json`"
            )
        
        # ××—×™×§×ª ×”×§×•×‘×¥ ×”×–×× ×™
        os.remove(filename)
        
    except Exception as e:
        await update.message.reply_text(f"âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª ×”×’×™×‘×•×™: {str(e)}")

def main():
    """×”×¤×¢×œ×ª ×”×‘×•×˜"""
    application = Application.builder().token(TELEGRAM_TOKEN).build()
    
    # ×”×•×¡×¤×ª handlers
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("saved", saved_articles))
    application.add_handler(CommandHandler("backup", backup_command))
    application.add_handler(CommandHandler("tag", tag_command))
    
    # ×˜×™×¤×•×œ ×‘×§×™×©×•×¨×™×
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_url))
    
    # ×˜×™×¤×•×œ ×‘×›×¤×ª×•×¨×™×
    application.add_handler(CallbackQueryHandler(button_callback))
    
    print("ğŸ¤– ×”×‘×•×˜ ××•×¤×¢×œ ×‘××¦×‘ polling...")
    print("ğŸ“± ×¤×§×•×“×ª /saved ×××•×¨×” ×œ×¢×‘×•×“ ×¢×›×©×™×•!")
    
    # ×”×¤×¢×œ×ª ×”×‘×•×˜ ×¢× Polling (×œ×¤×™×ª×•×— ××§×•××™)
    application.run_polling()

# Flask routes ×”×•×¡×¨×• - ×”×‘×•×˜ ×¢×•×‘×“ ×‘××¦×‘ polling

if __name__ == '__main__':
    main()
